{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f56d3f7-0a48-4261-993a-acc3fcc02595",
   "metadata": {},
   "source": [
    "## Install required Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9a94be-6b70-430c-a67d-a7c4d90b0684",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlflow==2.15.1 kserve==0.13.1 tenacity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e90e8b-6a60-4c1a-9dbf-98d1e3ea4ecc",
   "metadata": {},
   "source": [
    " ## Import the necessary components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "451c2635-f071-4879-a199-e26843cc1c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import mlflow\n",
    "import os\n",
    "import requests\n",
    "\n",
    "from kfp.dsl import Input, Model, component\n",
    "from kfp.dsl import InputPath, OutputPath, pipeline, component\n",
    "from kserve import KServeClient\n",
    "from mlflow.tracking import MlflowClient\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f6e739-d417-4c7a-b2cb-b5ff97e4913c",
   "metadata": {},
   "source": [
    "## Ingest your data\n",
    "Create a component that downloads the dataset, imports it as a .csv file and then saves it at a specified path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5d3c5b65-8e78-4fb0-a37a-ab905641d31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.11\",\n",
    "    packages_to_install=[\"requests==2.32.3\", \"pandas==2.2.2\"]\n",
    ")\n",
    "def download_dataset(url: str, dataset_path: OutputPath('Dataset')) -> None:\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    from io import StringIO\n",
    "    dataset = pd.read_csv(StringIO(response.text), header=0, sep=\";\")\n",
    "\n",
    "    dataset.to_csv(dataset_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b92d1d4-2fc2-41ad-bbb6-77811e120a26",
   "metadata": {},
   "source": [
    "## Process the data\n",
    "Create a component that preprocesses the dataset and saves it as an Apache Parquet file for a more efficient storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "434b75d7-6358-4b46-96c7-424082e232e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.11\",\n",
    "    packages_to_install=[\"pandas==2.2.2\", \"pyarrow==15.0.2\"]\n",
    ")\n",
    "def preprocess_dataset(dataset: InputPath('Dataset'), output_file: OutputPath('Dataset')) -> None:\n",
    "    import pandas as pd\n",
    "    \n",
    "    df = pd.read_csv(dataset, header=0)\n",
    "    df.columns = [c.lower().replace(\" \", \"_\") for c in df.columns]\n",
    "    df.to_parquet(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c363b3b-f28a-414f-a474-a07c5a9e6f88",
   "metadata": {},
   "source": [
    "## Train an ML model\n",
    "Now that the dataset is preprocessed, you can write a component that:\n",
    "* splits the dataset into training and testing data\n",
    "* trains an ElasticNet regression model\n",
    "* logs all model artefacts to MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fffa3adc-b491-4d2c-b11b-85c28b366185",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.11\",\n",
    "    packages_to_install=[\"pandas==2.2.2\", \"scikit-learn==1.5.1\", \"mlflow==2.15.1\", \"pyarrow==15.0.2\", \"boto3==1.34.162\"]\n",
    ")\n",
    "def train_model(dataset: InputPath('Dataset'), run_name: str, model_name: str) -> str:\n",
    "    import os\n",
    "    import mlflow\n",
    "    import pandas as pd\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    df = pd.read_parquet(dataset)\n",
    "    \n",
    "    target_column = \"quality\"\n",
    "\n",
    "    train_x, test_x, train_y, test_y = train_test_split(\n",
    "        df.drop(columns=[target_column]),\n",
    "        df[target_column], test_size=0.25,\n",
    "        random_state=42, stratify=df[target_column]\n",
    "    )\n",
    "\n",
    "    mlflow.sklearn.autolog()\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        mlflow.set_tag(\"author\", \"kf-testing\")\n",
    "        lr = ElasticNet(alpha=0.5, l1_ratio=0.5, random_state=42)\n",
    "        lr.fit(train_x, train_y)\n",
    "        mlflow.sklearn.log_model(lr, \"model\", registered_model_name=model_name)\n",
    "        \n",
    "        model_uri = f\"{run.info.artifact_uri}/model\"\n",
    "        print(model_uri)\n",
    "        return model_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0268a675-c24b-4bb5-938a-23f9d88df7d5",
   "metadata": {},
   "source": [
    "## Deploy the ML model\n",
    "After the model has been trained, you can create a KServe inference service to enable scalable and performant model inference using HTTP requests. See [KServe documentation](https://kserve.github.io/website/0.13/get_started/first_isvc/) for more details.\n",
    "Write a component that creates a KServe inference service and returns its URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "73341b5f-a41a-484e-b306-b3bf434acf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.11\",\n",
    "    packages_to_install=[\"kserve==0.13.1\", \"kubernetes==26.1.0\", \"tenacity==9.0.0\"]\n",
    ")\n",
    "def deploy_model_with_kserve(model_uri: str, isvc_name: str) -> str:\n",
    "    import os\n",
    "    from kubernetes.client import V1ObjectMeta, V1EnvVar, V1EnvVarSource, V1SecretKeySelector\n",
    "    from kserve import (\n",
    "        constants,\n",
    "        KServeClient,\n",
    "        V1beta1InferenceService,\n",
    "        V1beta1InferenceServiceSpec,\n",
    "        V1beta1PredictorSpec,\n",
    "        V1beta1SKLearnSpec,\n",
    "    )\n",
    "    from tenacity import retry, wait_exponential, stop_after_attempt\n",
    "\n",
    "    isvc = V1beta1InferenceService(\n",
    "        api_version=constants.KSERVE_V1BETA1,\n",
    "        kind=constants.KSERVE_KIND,\n",
    "        metadata=V1ObjectMeta(\n",
    "            name=isvc_name,\n",
    "            annotations={\"sidecar.istio.io/inject\": \"false\"},\n",
    "        ),\n",
    "        spec=V1beta1InferenceServiceSpec(\n",
    "            predictor=V1beta1PredictorSpec(\n",
    "                service_account_name=\"kserve-controller-s3\",\n",
    "                sklearn=V1beta1SKLearnSpec(\n",
    "                    storage_uri=model_uri,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    client = KServeClient()\n",
    "    client.create(isvc)\n",
    "\n",
    "    @retry(\n",
    "        wait=wait_exponential(multiplier=2, min=1, max=10),\n",
    "        stop=stop_after_attempt(30),\n",
    "        reraise=True,\n",
    "    )\n",
    "    def assert_isvc_created(client, isvc_name):\n",
    "        assert client.is_isvc_ready(isvc_name), f\"Failed to create Inference Service {isvc_name}.\"\n",
    "\n",
    "    assert_isvc_created(client, isvc_name)\n",
    "    isvc_resp = client.get(isvc_name)\n",
    "    isvc_url = isvc_resp['status']['address']['url']\n",
    "    print(\"Inference URL:\", isvc_url)\n",
    "\n",
    "    return isvc_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28235e10-f1eb-49b0-8d71-00255e422ef1",
   "metadata": {},
   "source": [
    "## Create a pipeline\n",
    "Create a pipeline that combines all the components you defined in the previous sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "578f2cd9-a5f6-4904-9891-e6c0cafec4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow_tracking_uri:  http://mlflow-server.kubeflow.svc.cluster.local:5000\n",
      "mlflow_s3_endpoint_url:  http://mlflow-minio.kubeflow:9000\n",
      "aws_access_key_id:  minio\n",
      "aws_secret_access_key:  GLHTXTABH3VK4KG1B7WBPUMXU875WM\n"
     ]
    }
   ],
   "source": [
    "ISVC_NAME = \"wine-regressor4\"\n",
    "MLFLOW_RUN_NAME = \"elastic_net_models\"\n",
    "MLFLOW_MODEL_NAME = \"wine-elasticnet\"\n",
    "\n",
    "mlflow_tracking_uri = os.getenv('MLFLOW_TRACKING_URI')\n",
    "mlflow_s3_endpoint_url = os.getenv('MLFLOW_S3_ENDPOINT_URL')\n",
    "aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "print(\"mlflow_tracking_uri: \", mlflow_tracking_uri)\n",
    "print(\"mlflow_s3_endpoint_url: \", mlflow_s3_endpoint_url)\n",
    "print(\"aws_access_key_id: \", aws_access_key_id)\n",
    "print(\"aws_secret_access_key: \", aws_secret_access_key)\n",
    "\n",
    "@pipeline(name='download-preprocess-train-deploy-pipeline')\n",
    "def download_preprocess_train_deploy_pipeline(url: str):\n",
    "    download_task = download_dataset(url=url)\n",
    "    \n",
    "    preprocess_task = preprocess_dataset(\n",
    "        dataset=download_task.outputs['dataset_path']\n",
    "    )\n",
    "    \n",
    "    train_task = train_model(\n",
    "        dataset=preprocess_task.outputs['output_file'], run_name=MLFLOW_RUN_NAME, model_name=MLFLOW_MODEL_NAME\n",
    "    ).set_env_variable(name='MLFLOW_TRACKING_URI', value=mlflow_tracking_uri)\\\n",
    "     .set_env_variable(name='MLFLOW_S3_ENDPOINT_URL', value=mlflow_s3_endpoint_url)\\\n",
    "     .set_env_variable(name='AWS_ACCESS_KEY_ID', value=aws_access_key_id)\\\n",
    "     .set_env_variable(name='AWS_SECRET_ACCESS_KEY', value=aws_secret_access_key)\n",
    "    \n",
    "    deploy_task = deploy_model_with_kserve(\n",
    "        model_uri=train_task.output, isvc_name=ISVC_NAME\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ad3e75-aa44-4430-a84c-ede4b9af94a9",
   "metadata": {},
   "source": [
    "## Execute the pipeline\n",
    "To execute the pipeline, you first have to initialise a Kubeflow Pipelines (KFP) client to interact with the Kubeflow Pipelines API. Then, you must compile the pipeline to a compatible YAML file and create a run from the produced YAML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6995f865-f2b2-423f-98fa-f28a61dd8b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/eab56b7f-f1ae-4d56-a13b-ae35c83302b6\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/7cbc87a7-9e68-43b8-9143-a7d7692a6291\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client = kfp.Client()\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/canonical/kubeflow-examples/main/e2e-wine-kfp-mlflow/winequality-red.csv'\n",
    "\n",
    "kfp.compiler.Compiler().compile(download_preprocess_train_deploy_pipeline, './pipelines-yaml/download_preprocess_train_deploy_pipeline.yaml')\n",
    "\n",
    "run = client.create_run_from_pipeline_func(download_preprocess_train_deploy_pipeline, arguments={'url': url}, enable_caching=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef07f11-ba6e-4922-9fe0-a59bbabcc019",
   "metadata": {},
   "source": [
    "## Test the deployed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b0011e3b-ba8a-46a4-8b21-8d5824359e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference URL: http://wine-regressor4.demo-ns.svc.cluster.local\n",
      "{\"predictions\":[5.575510497546586,5.527143590500911]}\n"
     ]
    }
   ],
   "source": [
    "kserve_client = KServeClient()\n",
    "\n",
    "isvc_resp = kserve_client.get(ISVC_NAME)\n",
    "inference_service_url = isvc_resp['status']['address']['url']\n",
    "print(\"Inference URL:\", inference_service_url)\n",
    "\n",
    "input_data = {\n",
    "    \"instances\": [\n",
    "        [7.4, 0.7, 0.0, 1.9, 0.076, 11.0, 34.0, 0.9978, 3.51, 0.56, 9.4],\n",
    "        [7.8, 0.88, 0.0, 2.6, 0.098, 25.0, 67.0, 0.9968, 3.2, 0.68, 9.8]\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{inference_service_url}/v1/models/{ISVC_NAME}:predict\", json=input_data)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a5e5b8-9990-4b89-b8d0-2cd510d0a859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
