{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bd92d6a-208c-49ec-9df4-5dc0eefe395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp.dsl import component, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d511c321-5af6-4272-821d-1d01420fa7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image='python:3.9',\n",
    "    packages_to_install=[\"git+https://github.com/kubeflow/trainer.git@master#subdirectory=sdk\"],\n",
    ")\n",
    "def deepspeed_training_job() -> str:\n",
    "    from kubeflow.trainer import CustomTrainer, TrainerClient\n",
    "\n",
    "    def deepspeed_train_t5(args):\n",
    "        import os\n",
    "        import time\n",
    "        import torch\n",
    "        import torch.distributed as dist\n",
    "        from torch.utils.data.distributed import DistributedSampler\n",
    "        from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "        from datasets import Dataset\n",
    "        import deepspeed\n",
    "        import numpy as np\n",
    "    \n",
    "        # Initialize distributed environment.\n",
    "        deepspeed.init_distributed(dist_backend=\"nccl\")\n",
    "        local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
    "    \n",
    "        # Define the Wikihow dataset class\n",
    "        class wikihow(torch.utils.data.Dataset):\n",
    "            def __init__(\n",
    "                self,\n",
    "                tokenizer,\n",
    "                num_samples,\n",
    "                input_length,\n",
    "                output_length,\n",
    "            ):\n",
    "                self.dataset = Dataset.from_csv(args[\"DATASET_URL\"])\n",
    "                self.dataset = self.dataset.select(list(range(0, num_samples)))\n",
    "                self.input_length = input_length\n",
    "                self.tokenizer = tokenizer\n",
    "                self.output_length = output_length\n",
    "    \n",
    "            def __len__(self):\n",
    "                return self.dataset.shape[0]\n",
    "    \n",
    "            def clean_text(self, text):\n",
    "                # Dataset contains empty values.\n",
    "                if text is None:\n",
    "                    return \"\"\n",
    "                text = text.replace(\"Example of text:\", \"\")\n",
    "                text = text.replace(\"Example of Summary:\", \"\")\n",
    "                text = text.replace(\"\\n\", \"\")\n",
    "                text = text.replace(\"``\", \"\")\n",
    "                text = text.replace('\"', \"\")\n",
    "    \n",
    "                return text\n",
    "    \n",
    "            def convert_to_features(self, example_batch):\n",
    "                input_ = self.clean_text(example_batch[\"text\"])\n",
    "                target_ = self.clean_text(example_batch[\"headline\"])\n",
    "    \n",
    "                source = self.tokenizer(\n",
    "                    input_,\n",
    "                    max_length=self.input_length,\n",
    "                    padding=\"max_length\",\n",
    "                    truncation=True,\n",
    "                    return_tensors=\"pt\",\n",
    "                )\n",
    "                targets = self.tokenizer(\n",
    "                    target_,\n",
    "                    max_length=self.output_length,\n",
    "                    padding=\"max_length\",\n",
    "                    truncation=True,\n",
    "                    return_tensors=\"pt\",\n",
    "                )\n",
    "    \n",
    "                return source, targets\n",
    "    \n",
    "            def __getitem__(self, index):\n",
    "                source, targets = self.convert_to_features(self.dataset[index])\n",
    "                return {\n",
    "                    \"source_ids\": source[\"input_ids\"].squeeze(),\n",
    "                    \"source_mask\": source[\"attention_mask\"].squeeze(),\n",
    "                    \"target_ids\": targets[\"input_ids\"].squeeze(),\n",
    "                    \"target_mask\": targets[\"attention_mask\"].squeeze(),\n",
    "                }\n",
    "    \n",
    "        # Download model and tokenizer\n",
    "        if dist.get_rank() == 0:\n",
    "            print(\"-\" * 100)\n",
    "            print(\"Downloading T5 Model\")\n",
    "            print(\"-\" * 100)\n",
    "    \n",
    "        model = T5ForConditionalGeneration.from_pretrained(args[\"MODEL_NAME\"])\n",
    "        tokenizer = T5Tokenizer.from_pretrained(args[\"MODEL_NAME\"])\n",
    "    \n",
    "        # Download dataset.\n",
    "        dataset = wikihow(tokenizer, num_samples=1500, input_length=512, output_length=150)\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            dataset, batch_size=4, sampler=DistributedSampler(dataset)\n",
    "        )\n",
    "    \n",
    "        # Define DeepSpeed configuration.\n",
    "        # Train batch size = micro batch size * gradient steps * GPUs (e.g. 2 x 1 x 8 = 16).\n",
    "        ds_config = {\n",
    "            \"train_micro_batch_size_per_gpu\": 2,\n",
    "            \"gradient_accumulation_steps\": 1,\n",
    "            \"fp16\": {\"enabled\": True},  # Enable mixed precision\n",
    "            \"optimizer\": {\n",
    "                \"type\": \"AdamW\",\n",
    "                \"params\": {\"lr\": 0.002},\n",
    "            },\n",
    "            \"scheduler\": {\n",
    "                \"type\": \"WarmupLR\",\n",
    "                \"params\": {\n",
    "                    \"warmup_min_lr\": 0,\n",
    "                    \"warmup_max_lr\": 0.001,\n",
    "                    \"warmup_num_steps\": 1000,\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    \n",
    "        # Initialize model with DeepSpeed.\n",
    "        model, _, _, _ = deepspeed.initialize(\n",
    "            config=ds_config,\n",
    "            model=model,\n",
    "            model_parameters=model.parameters(),\n",
    "        )\n",
    "    \n",
    "        # Start training process.\n",
    "        if dist.get_rank() == 0:\n",
    "            print(\"-\" * 100)\n",
    "            print(\"Starting DeepSpeed distributed training...\")\n",
    "            print(\"-\" * 100)\n",
    "    \n",
    "        t0 = time.time()\n",
    "        for epoch in range(1, 3):\n",
    "            losses = []\n",
    "            for batch_idx, batch in enumerate(train_loader):\n",
    "                for key in batch.keys():\n",
    "                    batch[key] = batch[key].to(local_rank)\n",
    "                # Forward pass.\n",
    "                output = model(\n",
    "                    input_ids=batch[\"source_ids\"],\n",
    "                    attention_mask=batch[\"source_mask\"],\n",
    "                    labels=batch[\"target_ids\"],\n",
    "                )\n",
    "                loss = output.loss\n",
    "    \n",
    "                # Run backpropagation.\n",
    "                model.backward(loss)\n",
    "                # Weight updates.\n",
    "                model.step()\n",
    "                losses.append(loss.item())\n",
    "                if batch_idx % 10 == 0 and dist.get_rank() == 0:\n",
    "                    print(\n",
    "                        \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                            epoch,\n",
    "                            batch_idx * len(batch),\n",
    "                            len(train_loader.dataset),\n",
    "                            100.0 * batch_idx / len(train_loader),\n",
    "                            loss.item(),\n",
    "                        )\n",
    "                    )\n",
    "    \n",
    "            if dist.get_rank() == 0:\n",
    "                print(\"-\" * 100)\n",
    "                print(\"Average Train Loss: {0:.4f}\".format(np.mean(losses)))\n",
    "                print(\"-\" * 100)\n",
    "    \n",
    "        # Export model to S3.\n",
    "        HOME_PATH = \"/home/mpiuser\"\n",
    "        model.save_checkpoint(save_dir=HOME_PATH)\n",
    "    \n",
    "        if dist.get_rank() == 0:\n",
    "            print(\"-\" * 100)\n",
    "            print(f\"DeepSpeed training time: {int(time.time() - t0)} seconds\")\n",
    "            print(\"-\" * 100)\n",
    "    \n",
    "            print(\"Upload T5 model to S3??\")\n",
    "            file_path = os.path.join(HOME_PATH, \"global_step94/mp_rank_00_model_states.pt\")\n",
    "            print(file_path)\n",
    "            # bucket = boto3.resource(\"s3\").Bucket(args[\"BUCKET\"])\n",
    "            # bucket.upload_file(file_path, f\"deepspeed/{file_path}\")\n",
    "            dist.destroy_process_group()\n",
    "    \n",
    "    \n",
    "    MODEL_NAME = \"t5-base\"\n",
    "    BUCKET_NAME = \"deepseek-t5-base\"\n",
    "    args = {\n",
    "        \"DATASET_URL\": \"https://public-nlp-datasets.s3.us-west-2.amazonaws.com/wikihowAll.csv\",\n",
    "        \"MODEL_NAME\": MODEL_NAME,\n",
    "        \"BUCKET\": BUCKET_NAME\n",
    "    }\n",
    "\n",
    "    for r in TrainerClient().list_runtimes():\n",
    "        print(f\"Name: {r.name}, Framework: {r.trainer.framework.value}, Trainer Type: {r.trainer.trainer_type.value}\\n\")\n",
    "        print(f\"Entrypoint: {r.trainer.entrypoint[:3]}\\n\")\n",
    "        print(f\"Runtime Accelerators: {r.trainer.accelerator_count} x {r.trainer.accelerator}\")\n",
    "    \n",
    "        if r.name == \"deepspeed-distributed\":\n",
    "            deepspeed_runtime = r\n",
    "    \n",
    "    job_id = TrainerClient().train(\n",
    "        trainer=CustomTrainer(\n",
    "            func=deepspeed_train_t5,\n",
    "            func_args=args,\n",
    "            packages_to_install=[\"boto3\"], # Custom packages to install at runtime.\n",
    "            num_nodes=2,\n",
    "            resources_per_node={\n",
    "                \"cpu\": 5,\n",
    "                \"memory\": \"16Gi\",\n",
    "                \"gpu\": 1, # Comment this line if you don't have GPUs.\n",
    "            },\n",
    "        ),\n",
    "        runtime=deepspeed_runtime,\n",
    "    )\n",
    "    \n",
    "    print(job_id)\n",
    "    \n",
    "    for s in TrainerClient().get_job(name=job_id).steps:\n",
    "        print(f\"Step: {s.name}, Status: {s.status}, Devices: {s.device} x {s.device_count}\")\n",
    "\n",
    "    return job_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9e60d32-8167-426c-bbce-9a91f4d7ddaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{{channel:task=deepspeed-training-job;name=Output;type=String;}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/eab56b7f-f1ae-4d56-a13b-ae35c83302b6\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/e1207442-058c-4f50-bc79-46984d21c531\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@pipeline(name='deepspeed-training-job-pipeline')\n",
    "def deepspeed_training_job_pipeline():\n",
    "    step1 = deepspeed_training_job()\n",
    "    print(step1.output)\n",
    "\n",
    "client = kfp.Client()\n",
    "kfp.compiler.Compiler().compile(deepspeed_training_job_pipeline, 'deepspeed_training_job_pipeline.yaml')\n",
    "run = client.create_run_from_pipeline_func(deepspeed_training_job_pipeline, arguments={}, enable_caching=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5844c0c4-9152-444b-80b6-681252a65e13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
