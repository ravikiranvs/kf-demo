{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b3cbd08-cf40-434e-8d56-b3916a7e0899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import os\n",
    "import requests\n",
    "\n",
    "from kfp.dsl import Input, Model, component, Dataset, Output, Artifact\n",
    "from kfp.dsl import InputPath, OutputPath, pipeline, component, PipelineTask\n",
    "from kfp.components import load_component_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa49f7f9-968c-4e30-9adf-eaffc3b2788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.11\",\n",
    "    packages_to_install=[\"accelerate\", \"transformers[torch]\", \"transformers\", \"datasets\", \"huggingface_hub\"]\n",
    ")\n",
    "def download_model_hf(model_name: str, dataset_name: str, model_archive: Output[Artifact], data_archive: Output[Artifact]) -> None:\n",
    "    from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "    from datasets import load_dataset\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        \n",
    "    # Format: turn (question + schema) -> cypher\n",
    "    def data_formatter(example):\n",
    "        prompt = f\"## Schema:\\n{example['schema']}\\n\\n## Question:\\n{example['question']}\\n\\nCypher:\\n\"\n",
    "        return {\n",
    "            \"prompt\": prompt,\n",
    "            \"completion\": example[\"cypher\"]\n",
    "        }\n",
    "\n",
    "    # Tokenize\n",
    "    def tokenize_function(example):\n",
    "        return tokenizer(\n",
    "            example[\"prompt\"] + example[\"completion\"],\n",
    "            truncation=True,\n",
    "            padding=False,\n",
    "            max_length=512\n",
    "        )\n",
    "\n",
    "    # Ensure labels = input_ids (common for causal LM)\n",
    "    def format_for_training(example):\n",
    "        example[\"labels\"] = example[\"input_ids\"]\n",
    "        return example\n",
    "\n",
    "    model.save_pretrained(model_archive.path)\n",
    "    tokenizer.save_pretrained(model_archive.path)\n",
    "    \n",
    "    dataset = load_dataset(dataset_name)\n",
    "    dataset = dataset.map(data_formatter)\n",
    "    dataset = dataset.map(tokenize_function)\n",
    "    dataset = dataset.map(format_for_training)\n",
    "\n",
    "    dataset.save_to_disk(data_archive.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ec1d180-5275-47c8-bf0b-46646624a3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.11\",\n",
    "    packages_to_install=[\"accelerate\", \"transformers[torch]\", \"transformers\", \"datasets\", \"huggingface_hub\", \"peft\", \"evaluate\"]\n",
    ")\n",
    "def train_model(model_archive: Input[Artifact], data_archive: Input[Artifact], trained_model_archive: Output[Artifact]) -> None:\n",
    "    from datasets import DatasetDict, Dataset, load_from_disk\n",
    "    from transformers import AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "    from peft import get_peft_model, LoraConfig, TaskType\n",
    "    import evaluate\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(model_archive.path)\n",
    "    \n",
    "    dataset = load_from_disk(data_archive.path)\n",
    "    dataset_train = dataset[\"train\"].shuffle(seed=47)\n",
    "    dataset_test = dataset[\"test\"].shuffle(seed=47)\n",
    "\n",
    "    lora_config = LoraConfig(\n",
    "        r=8,\n",
    "        lora_alpha=16,\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],  # adjust based on your model\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=TaskType.CAUSAL_LM\n",
    "    )\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    model.print_trainable_parameters()\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=trained_model_archive.path,\n",
    "        eval_strategy=\"epoch\",\n",
    "        push_to_hub=False,\n",
    "        fp16=True,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset_train,\n",
    "        eval_dataset=dataset_test,\n",
    "    )\n",
    "    \n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23ff8cdb-f1a9-4464-a5b9-8feaef870712",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(name='finetune-pipeline')\n",
    "def finetune_pipeline(model_name: str, dataset_name: str) -> None:\n",
    "    hf_download_op = download_model_hf(model_name=model_name, dataset_name=dataset_name)\n",
    "    training_op = train_model(model_archive=hf_download_op.outputs['model_archive'], data_archive=hf_download_op.outputs['data_archive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "727c598f-60d9-40b5-944e-03900fdc4726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/eab56b7f-f1ae-4d56-a13b-ae35c83302b6\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/d69dc06d-b114-462b-a5a4-098837f60cf2\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client = kfp.Client()\n",
    "\n",
    "run = client.create_run_from_pipeline_func(finetune_pipeline, arguments={\"model_name\": \"codellama/CodeLlama-7b-hf\", \"dataset_name\": \"neo4j/text2cypher-2025v1\"}, enable_caching=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c832d75d-bcd6-43fc-a9ad-c13061a3127d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2caaac-bc7f-46f9-aefc-33e9bb95489f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
